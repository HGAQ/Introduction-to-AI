# AI引论

## Chap01 概论

## Chap02 数学基础

- **样本空间&样品点**
  - **样本空间**：所有可能的结果
  - **样本点**：样本空间元素
- **随机事件**
  - 满足某些条件的样本点组成的集合。它是样本空间 Ω 的子集，记为 𝐴,𝐵, ...
  - 关系
    - 包含，并，交，对立（是和不是），互斥（红灯和绿灯（还有黄灯））
- **古典概型**
  - **有限性**：只有有限个试验结果（样本）
  - **等可能性**：每个试验结果（样本）在一次试验中出现的可能性相等；
- **条件概率**
  - 在事件𝐵已经出现的条件下，事件𝐴发生的概率，记作 P(A | B).
  - **P(A | B) = P(A ∩ B) / P(B)** => **P(A ∩ B)=P(A | B) · P(B)**
- **独立事件**
  - 若 P(AB) = P(A) · P(B),则**相互独立**。
  - 若 P(ABCDEFG) = P(A) P(B) …… P(G)，则**相互独立**。
  - 若 P(AB) = P(A) · P(B)；P(CB) = P(C) · P(B)；P(AC) = P(A) · P(C)，则**两两独立**。
  - 两两独立的事件组**不一定**相互独立。
  - 相互独立的事件组**一定**两两独立。
- **全概率公式**
  - ![1](https://pic.imgdb.cn/item/63f71c5ff144a010073f3d26.jpg)
  - ![2](https://pic.imgdb.cn/item/63f71c82f144a010073f73f4.jpg)
  - ![3](https://pic.imgdb.cn/item/63f71cd1f144a010073ff0c5.jpg)
- **贝叶斯公式**
  - ![4](https://pic.imgdb.cn/item/63f72553f144a010074e3223.jpg)
- **随机变量**
  - ![5](https://pic.imgdb.cn/item/63f751c8f144a0100797e05b.jpg)
  - ![6](https://pic.imgdb.cn/item/63f751f2f144a01007981ade.jpg)
  - ![7](https://pic.imgdb.cn/item/63f7520af144a01007983a5b.jpg)
- **数学期望**
  - ![8](https://pic.imgdb.cn/item/63f75234f144a0100798720b.jpg)
  - ![9](https://pic.imgdb.cn/item/63f7524bf144a01007989334.jpg)
- **方差与标准差**
  - ![10](https://pic.imgdb.cn/item/63f7525ff144a0100798b02d.jpg)
  - 方差的算术平方根 $\sqrt{𝐷(X)}$ 称为 X 的标准差或均方差，记为σ (X)
- **协方差**
  - 若随机变量 𝑋 的期望 𝐸(𝑋) 和 𝑌 的期望 𝐸(𝑌) 存在，则称
  - $$Cov(X,Y)=E{[X-E(x)\][Y-E(Y)]}$$
    为 𝑋 与 𝑌 的协方差。
  - 若随机变量 𝑋，𝑌的方差和协方差均存在，且 𝐷(𝑋) > 0，𝐷(𝑌) > 0，则
  - $$ρ(X,Y)=\frac{Cov(X,Y)}{\sqrt{D(X)·D(Y)}}$$称为 𝑋，𝑌 的相关系数。

## Chap03 python

- intended left blank

## Chap04-05 搜索

- 目标（goal）：即我们要去“找”什么；什么时候可以结束搜索
- 状态（state）：这里面其实包括三个主要的部分，开始状态（initial states），目标状态（goal states），当前状态（current state）
- 动作（actions）：智能体可以采取的行动/决策
- （状态）转移模型（transition model）：当前状态随着动作会怎么变化
- 动作代价函数（action cost function）：每个动作要消耗多大的成本
- 深度优先搜索：DFS
  - 一条路走到黑，不撞南墙不回头
  - stack！！！（后进先出）
  - 不是代价最小的，也不是最短的
- 广度优先搜索：BFS
  - 搜索一步的所有情况
  - queue！！！（先进先出）
  - 最短但是不是代价最小的
- 一致代价搜索：UFS
  - 我们不应该只关注单边的成本，而是要考虑总成本（从开始节点累积到当前节点），广搜是UFS的一种
  - 代价->步骤
  - 代价轮廊
  - priority queue！！（优先队列）
    - 保存所有节点与优先值
    - 优先队列通常依靠 堆（heap）来实现
    - 依靠树的层级来维持顺序，父母节点一定小于等于孩子节点（树是完整的，即只有最底层的右边有空缺）
  - 假设最佳答案是有限代价，并且边的最低代价是正的，算法完备且最优。
  - **没有考虑关于目标的信息**
- 启发算法
  - 启发(heuristic)是一个估计当前状态离目标状态还有多“远”的方程
- 贪心搜索
  - 永远扩展看起来最近的（启发告诉我们离目标最近的节点）
  - 不是最优
  - 最差情况: 像一个被错误引导的深搜，最后导致要扩展完整个搜索空间才能到目标
- A*
  - UCS 向后看，根据至今积累的代价排序 g(n)
  - 贪心 向前看, 根据离目标还有多远的估计排序 h(n)
  - A* 根据两者的和决定顺序 : f(n) = g(n) + h(n)
  - 一个启发 ℎ 是 可接受的 (乐观的)，需满足:
    - 启发小于代价，单边的启发值小于实际动作代价
    - 从而，在一条路径下f永远不会减小
  - $$ 0≤h(n)≤h^*(n)$$

$$ g(E) = \frac{8\pi}{3h^3}(2m)^{3/2}E^{1/2} $$

## Chap06 逻辑与CSP

- 变量、域、约束、目标
- 回溯搜索：
  - 先考虑一个变量，然后每一步判断若不符合就回退。
  - 25皇后
- 改进：
  - 顺序：
    - 最少剩余值启发：选择可能性最少的变量赋值
    - 当一个变量被赋值的时候，选择给剩下的变量留下最多选择的值。
  - 筛选：
    - 约束传递: 从约束推理到约束
    - 一条边 X → Y 是一致的：对于每一个X的剩余值，Y都有某个赋值方式，使其不会违反约束
- SAT问题：是否存在一种布尔赋值组合，使所有的逻辑约束都能被满足
  - 将问题变为布尔运算
  - DPLL算法：
    - 合取范式（CNF）： (p1∨¬p3∨p4 ) ∧ (¬p1∨p2∨¬p3 ) ∧ ...
      - 就是每一个都要真
    - 单字符传递（unit propagation）：当某个子句只剩下一个字符，对这个变量赋值使子句为真
    - 布尔约束传递(BCP):重复使用单字符传递，直到无法使用为止
    - （就是深搜……
  - 矛盾指引的子句学习算法:
    - 隐含图（implication graph）：对于SAT的搜索树，我们有两种主要赋值方式，手动赋值，和由BCP产生的赋值。
    - 通过已有的条件推出越来越多的矛盾语句
    - 对于完全可观察的、确定性的情况:
      - 规划问题是可解的 当且仅当 存在可满足的赋值
      - 解法从动作变量的赋值获得

## Chap07 对抗博奕

- 零和博弈(Zero-Sum Games )
  - 效用：关于回报大小的度量
  - 智能体的效用是对立的，比如：当一个智能体最大化其效用时，另一智能体效用为其最小值
  - 特点：对抗的(adversarial), 完全竞争(purecompetition)
- 一般博弈(General Games)
  - 智能体获得的效用是独立的
- 搜索：代价(cost) -> 效用(utility)!
  - 状态价值: 从该状态出发可能获得的最大最终效用
  - 效率如何？
    - 与DFS一致
    - 时间复杂度: 𝑂(𝑏^𝑚)
    - 空间复杂度: 𝑂(𝑏m)
- 确定性零和博弈:
  - 井字棋, 国际象棋, 跳棋、围棋
  - 其中一个玩家最大化价值，对手玩家最小化价值

- 极小极大搜索:
  - 状态空间的搜索树
  - 玩家轮流行动
  - 计算每个节点极大极小价值: 假设对手是理性的情况下（即对方总是努力达到最优），自己可以达到的最优效用值

## Chap08 蒙特卡洛搜索

- 蒙特卡洛搜索（MCTS）
  - 利用（大规模）随机抽样来近似问题的解
  - 20世纪40年代，一群从事核弹制造的科学家以蒙特卡洛赌场命名
  - 次数越多越准确
    - 估计的准确度与样本方差有关
    - ![mtkl](https://pic.imgdb.cn/item/6417f363a682492fcc72ccb3.jpg)
- 𝜀-greedy
  - 1- 𝜀的时候：选当前最优的
  - 𝜀的时候：随机选取一个当前不是最优的
    - 如果我们可以更多地去尝试那些更有希望成为更优的动作，算法的效率将更高
- 最大置信（UCB）
  - 尝试次数越多估值越准确，也即我们对尝试次数少的估计信任不足
  - 算法应平衡 估值的大小 和 次数的多少
  - $$A_{t+1}=argmax_a[Q_t(a)+c\sqrt{\frac{lnt}{N_t(a)}}]$$
  - 𝑐: 超参数，用于平衡估值和信任度对决策的影响
- 博弈
  - ![mtkl2](https://pic.imgdb.cn/item/6417f8c4a682492fcc7e5c8f.jpg)
  - **选择 扩展 模拟 回溯**
  - 选择:
    - 每个圆圈都包含获胜次数 / 通过该节点次数
      - 在根节点，执行UCB
        - （c设为0.5）
        - 自左至右：1.05 0.97 0.67
      - 在2/3节点，执行UCB
        - 自左至右：0.52 0.87
  - 扩展：
    - 选择一次随机移动并扩展一个新的节点（加粗），初始化为0/0
  - 模拟：
    - 在实际使用MCTS的时候，模拟经常不会选择一直运行到博弈结束。而是会设设置一个最大步数，然后直接返回启发值。
  - 回溯：
    - 在模拟结束后，所采取路径上的所有记录都会被更新
    - 每个相关节点的次数都会加1，如果最后获胜了每个相关节点都会将胜利次数加1，这在加粗的数字中显示
  - 再次选择………………

## Chap09 机器学习与线性回归

- 特征提取
- 模型训练
- 模型评估
  - 训练误差 (training error): 在训练集上的平均误差
    - 通过最小化训练误差来训练模型
    - 对分类问题，通常用错误率来衡量训练误差。即，分类错误的样本 / 总样本数
  - 测试误差 (test error): 在测试集上的平均误差
    - 训练完成后，用来真正衡量模型在新数据上的好坏
    - 衡量模型的泛化 (generalization) 能力
    - 训练误差低不代表测试误差一定也低——过拟合
  - **过拟合** (overfitting): 测试误差远远大于训练误差
    - 错把训练样本中找到的特殊规律当做了普遍规律——应避免这种现象
  - **欠拟合** (underfitting): 训练完成后，训练误差仍然很大
    - 说明连训练样本都没有拟合好
- **k近邻(k-NN)算法**
  - 对于一个测试样本，用训练样本中距离它最近的k个样本中占多数的标签来预测测试样本
  - 优点：
    - 不需要训练
    - 只需要一个距离函数即可，默认为欧氏距离
  - 缺点：
    - 需要存储所有训练样本
    - 在测试时需要计算测试样本到所有训练样本的距离
    - 有时很难找到一个好的距离函数
  - **非参数化模型**
    - 模型不能被有限参数 (parameters) 定义，或不包含参数
    - 需要保留训练样本，以对测试样本做出预测
    - eg.k-NN
  - **参数化模型**
    - 模型包含可训练的参数，通过拟合训练数据来估算模型参数
    - 训练好模型参数后，可以丢弃训练数据，仅依靠模型参数去预测新样本
    - 可以写成 y≈f(x) , 𝑓为包含参数的模型
    - eg.线性回归
- **线性模型**
  - $f(x)=w^Tx+b$
  - $x,w∈R^d$
  - x:输入 w:参数 b:偏置
  - 训练：通过最小化损失函数 (loss function) a.k.a 最小二乘法 (least squares)
    - $L(f(x_i),y_i)=(f(x_i)-y_i)^2$
    - 通过在训练集上最小化平均损失函数来优化参数w,b
    - **梯度下降**
      - 将要优化的目标 (objective) 写作变量 𝑤, 𝑏 的函数
      - $$J(w,b)=\frac{\sum_{i∈[n]}^{}L(f(x_i),y_i)}{n}$$
      - 选定初值，逐步调整w,b, 使得J(w,b)下降
      - 每次沿着使得J(w,b)变小最快的方向上走一小步
      - $$w<-w-α·\frac{∂J(w,b)}{∂w}$$  
      - $$ b<-b-α·\frac{∂J(w,b)}{∂b}$$
      - $$\frac{∂J(w,b)}{∂w}=[\frac{∂J(w,b)}{∂w_1},\frac{∂J(w,b)}{∂w_2},…,\frac{∂J(w,b)}{∂w_d}]^T=\nabla J(w,b)$$
      - α: 学习率 (learning rate)，是一个事先指定的超参数 (hyper-parameter)，不随𝑤, 𝑏 一起优化
      - 相当于在每个维度上，沿着负偏导的方向移动一定距离，距离正比于偏导的绝对值，比例为 α
      - 梯度给出了在所有可能方向上移动相同小距离使函数值上升最快的方向, 梯度下降：在使函数下降最快的方向（负梯度）上走一个小步长
      - 迭代直到J(w,b)无法再下降（比如两次的差小于1e-4）或达到预设的最大次数
    - 局部最小值和全局最小值
      - ![111](https://pic.imgdb.cn/item/642a6998a682492fccfbe25e.jpg)
      - 全局最小值一定是局部最小值，我们可以罗列所有局部最小值，取其中最小的就是全局最小值
      - 当f(x)是个凸函数（convex function）时反向成立
      - 最小化凸函数称为凸优化，对于凸优化我们可以方便地找到全局最小点，例如使用梯度下降
      - 如果学习率𝛼过大会无法收敛。但是学习率过小也会导致收敛缓慢因此，要选择适中的学习率，或逐步减小学习率
      - 损失函数J(w,b)是关于$[w^T,b]^T$的凸函数 （Hessian半正定）,因此可以采用梯度下降找到全局最小值
- _**SUMMARY:**_
  ![sum](https://pic.imgdb.cn/item/642a6b2ea682492fccfe04ab.jpg)

## Chap10 逻辑回归，多分类与正则化

- 经验风险最小化框架 Empirical Risk Minimization (ERM)
  - 首先确定采用的模型
  - 其次，确定损失函数
  - 在训练集上最小化损失函数的平均值
  - 一般都可以采用梯度下降优化参数
  - 大部分监督学习算法都遵循以上经验风险最小化框架 (ERM)，区别仅在于具体选择的 𝑓(x) 和 𝐿(𝑓(x), 𝑦).
- 逻辑回归 (Logistic Regression)
  - 处理二分类问题 （虽然名字叫回归）
  - 交叉熵损失函数 (cross entropy loss)
  - $sign(f(x)):\begin{cases} 1\ \ \ \ if\ f(x)>0\\ -1\ \ \ \ if\ f(x)<0\end{cases}$
- 最大似然框架
  - 让我们使用最大似然估计 (Maximum Likelihood Estimation) 来推导适合二分类问题的损失函数
  - 对观测数据进行（条件）概率建模
    - 对机器学习，每个观测数据即一个训练样本
    - 对判别式模型，我们只建模 $p(y|x;θ)$,θ为模型参数
  - 通过最大化观测数据在给定概率模型下的似然（把训练样本预测为正确标签的概率）来估计模型参数
  - 如果训练样本互相独立（独立同分布假设），则最大似然估计可写为
  - $$max\prod_{i∈[n]}^{}p(y=y_i|x=x_i;θ)$$
  - => $$max\ log(\prod_{i∈[n]}^{}p(y=y_i|x=x_i;θ))=max\ \sum_{i∈[n]}^{}log(p(y=y_i|x=x_i;θ))$$
  - 采用sigmoid函数: $σ:(-∞,+∞)->[0,1] σ(x)=\frac{1}{1+e^{-x}}$
    - 将实值 𝑓(𝑥) 转换为取正类 (𝑦 = 1) 的概率
    - 有 $1-σ(x)=σ(-x)$
    - 且有 $f(x)=w^Tx+b$
    - 则有
      - $$p(y=1|x;θ)=p(y=1|x;w,b)=σ(f(x))=σ(y·f(x))$$
      - $$p(y=-1|x;θ)=p(y=-1|x;w,b)=1-σ(f(x))=σ(-f(x))=σ(y·f(x))$$
  - 在训练集上最大化对数似然
    - 代入可得
    - $$min\frac{1}{n}\sum{i∈[n]}{}log[1+e^{-y_i(w^Tx_i+b)}]$$
    - 称为交叉熵损失 (Cross Entropy Loss) ，有时也直接称为 Logistic/Log Loss
    - 交叉熵损失函数可微、连续、且是凸函数 (convex)，因此容易优化
    - ![22](https://pic.imgdb.cn/item/642a77b3a682492fcc125b6f.jpg)
  - 把样本 𝑖 预测为其真实标签的概率越接近1（说明已经充分拟合该样本），它对梯度的贡献越小
  - 
